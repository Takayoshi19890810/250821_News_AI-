# main.py  â€” æŒ‡å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»F/Gåˆ—åæ˜ ç‰ˆ
import os
import sys
import json
from datetime import datetime, timedelta, timezone
from zoneinfo import ZoneInfo
from dateutil import parser as duparser

import gspread

# é«˜ç²¾åº¦ãªUnicodeæ­£è¦è¡¨ç¾ï¼ˆä»»æ„ï¼‰
try:
    import regex as re_u  # pip install regex
except Exception:
    re_u = None

# åŠè§’çµ±ä¸€ç”¨
import unicodedata
try:
    import jaconv  # pip install jaconv
except Exception:
    jaconv = None

# Geminiï¼ˆä»»æ„ï¼‰
try:
    import google.generativeai as genai
except Exception:
    genai = None


# ====== è¨­å®š ======
# å…¥åŠ›å´ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹åé›†çµæœãŒå…¥ã‚‹ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼‰
INPUT_SPREADSHEET_ID = os.getenv(
    "INPUT_SPREADSHEET_ID",
    "1RglATeTbLU1SqlfXnNToJqhXLdNoHCdePldioKDQgU8"  # æ—¢å®š: æ—¥ç”£ãƒ‹ãƒ¥ãƒ¼ã‚¹é›†è¨ˆ
)
# å‡ºåŠ›å´ï¼ˆæŠ½å‡ºãƒ»åˆ†é¡ã®çµæœã‚’æ›¸ãè¾¼ã‚€ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆï¼‰
OUTPUT_SPREADSHEET_ID = os.getenv(
    "OUTPUT_SPREADSHEET_ID",
    "1bi9U5y5k0EqF4lTgISSPvh8H_2dc8PUA2U3W0gulRbM"  # æ—¢å®š: ã”æç¤ºã®ã‚·ãƒ¼ãƒˆ
)
INPUT_SHEETS = ["MSN", "Google", "Yahoo"]

# å‡ºåŠ›åˆ—ï¼ˆAã€œIï¼‰:
# A=ã‚½ãƒ¼ã‚¹, B=ã‚¿ã‚¤ãƒˆãƒ«, C=URL, D=æŠ•ç¨¿æ—¥, E=å¼•ç”¨å…ƒ, F=ãƒã‚¸ãƒã‚¬, G=ã‚«ãƒ†ã‚´ãƒª, H=é‡è¤‡ç¢ºèªç”¨ã‚¿ã‚¤ãƒˆãƒ«, I=æœ‰æ–™ã‚«ãƒ†ã‚´ãƒª
OUTPUT_HEADERS = [
    "ã‚½ãƒ¼ã‚¹", "ã‚¿ã‚¤ãƒˆãƒ«", "URL", "æŠ•ç¨¿æ—¥", "å¼•ç”¨å…ƒ",
    "ãƒã‚¸ãƒã‚¬", "ã‚«ãƒ†ã‚´ãƒª", "é‡è¤‡ç¢ºèªç”¨ã‚¿ã‚¤ãƒˆãƒ«", "æœ‰æ–™ã‚«ãƒ†ã‚´ãƒª"
]

JST = ZoneInfo("Asia/Tokyo")


def jst_now():
    return datetime.now(tz=JST)


def yymmdd_jst(dt: datetime) -> str:
    return dt.strftime("%y%m%d")


def calc_time_window(now_jst: datetime):
    """
    æŠ½å‡ºç¯„å›²ï¼šå‰æ—¥15:00ï¼ˆå«ã‚€ï¼‰ã€œ å½“æ—¥14:59:59ï¼ˆå«ã‚€ï¼‰
    """
    end = now_jst.replace(hour=14, minute=59, second=59, microsecond=0)
    start = (end - timedelta(days=1)).replace(hour=15, minute=0, second=0, microsecond=0)
    return start, end


def parse_sheet_datetime_to_jst(val):
    """
    Cåˆ—ã€ŒæŠ•ç¨¿æ—¥ã€ã‚’ JST ã® datetime ã«å¤‰æ›ã€‚
    - æ•°å€¤ï¼ˆã‚·ãƒªã‚¢ãƒ«ï¼‰ï¼š1899-12-30 èµ·ç‚¹â†’JST
    - æ–‡å­—åˆ—ï¼šdateutilã§æŸ”è»Ÿãƒ‘ãƒ¼ã‚¹ï¼ˆTZç„¡â†’JSTæƒ³å®šï¼‰
    """
    if val is None or str(val).strip() == "":
        return None

    # æ•°å€¤ã‚·ãƒªã‚¢ãƒ«
    try:
        serial = float(val)
        base = datetime(1899, 12, 30, tzinfo=timezone.utc)
        dt_utc = base + timedelta(days=serial)
        return dt_utc.astimezone(JST)
    except Exception:
        pass

    # æ–‡å­—åˆ—
    try:
        dt = duparser.parse(str(val), fuzzy=True)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=JST)
        else:
            dt = dt.astimezone(JST)
        return dt
    except Exception:
        return None


def format_compact_jst(dt: datetime) -> str:
    """
    æŠ•ç¨¿æ—¥ã®æ›¸å¼ã‚’ `25/8/20 15:01` ã«çµ±ä¸€ï¼ˆå¹´=ä¸‹2æ¡ã€æœˆæ—¥=ã‚¼ãƒ­åŸ‹ã‚ç„¡ã—ï¼‰
    """
    return f"{dt:%y}/{dt.month}/{dt.day} {dt:%H:%M}"


# --- æ–‡å­—ç¨®ã®åŠè§’çµ±ä¸€ï¼ˆã‚«ã‚¿ã‚«ãƒŠãƒ»æ•°å­—ãƒ»è‹±å­—ï¼‰ ---
def to_hankaku_kana_ascii_digit(s: str) -> str:
    """
    ãƒ»æ•°å­—/è‹±å­—ã¯ NFKC ã§å…¨è§’â†’åŠè§’ã¸
    ãƒ»ã‚«ã‚¿ã‚«ãƒŠã¯ jaconv ãŒã‚ã‚Œã° z2h(kana=True) ã§åŠè§’åŒ–
      ï¼ˆãªã‘ã‚Œã°é•·éŸ³ç­‰ã¯æ®‹ã‚‹ãŒã€å®Ÿå®³ã‚’æœ€å°åŒ–ï¼‰
    """
    if not s:
        return ""
    # æ•°å­—ãƒ»è‹±å­—ã¯ NFKC ã§åŠè§’åŒ–ï¼ˆå…¨è§’â†’ASCIIï¼‰
    s_nfkc = unicodedata.normalize("NFKC", s)

    # ã‚«ã‚¿ã‚«ãƒŠåŠè§’åŒ–ï¼ˆå¯èƒ½ãªã‚‰ï¼‰
    if jaconv is not None:
        # ascii/digit ã‚‚ True ã«ã—ã¦å®‰å…¨å´ã§å…¨åŠè§’æ··åœ¨ã‚’è§£æ¶ˆ
        s_nfkc = jaconv.z2h(s_nfkc, kana=True, digit=True, ascii=True)
    return s_nfkc


def normalize_title_for_dup(s: str) -> str:
    """
    Håˆ—ï¼ˆé‡è¤‡ç¢ºèªç”¨ï¼‰ç”Ÿæˆï¼š
      1) ã‚«ã‚¿ã‚«ãƒŠãƒ»æ•°å­—ãƒ»ã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆã‚’åŠè§’ã¸çµ±ä¸€
      2) è¨˜å·ãƒ»æ‹¬å¼§é¡ãƒ»ç©ºç™½é¡ã‚’åŒ…æ‹¬é™¤å»ï¼ˆâ€œâ€, (), ï¼ˆï¼‰, ã€Šã€‹, ï¼»ï¼½, å¼•ç”¨ç¬¦, ãƒ€ãƒƒã‚·ãƒ¥, é•·éŸ³è¨˜å· ç­‰ï¼‰
      3) ä½™åˆ†ãªåŒºåˆ‡ã‚Šã‚’é™¤ã„ã¦æ¯”è¼ƒç”¨ã®ã‚·ãƒ³ãƒ—ãƒ«æ–‡å­—åˆ—ã‚’å‡ºåŠ›
    """
    if not s:
        return ""

    # 1) åŠè§’çµ±ä¸€
    s = to_hankaku_kana_ascii_digit(s)

    # 2) è¨˜å·é¡ã®é™¤å»
    if re_u:
        # \p{P}=å¥èª­ç‚¹, \p{S}=è¨˜å·, \p{Z}=åŒºåˆ‡ã‚Šï¼ˆã‚¹ãƒšãƒ¼ã‚¹ç­‰ï¼‰, \p{Cc}=åˆ¶å¾¡
        s = re_u.sub(r'[\p{P}\p{S}\p{Z}\p{Cc}]+', '', s)
    else:
        import re
        dash_chars = r'\-\u2212\u2010\u2011\u2012\u2013\u2014\u2015\uFF0D\u30FC\uFF70'
        pattern = (
            r'[\s"\'\u201C\u201D\u2018\u2019\(\)\[\]{}<>]'              # ç©ºç™½ã¨å„ç¨®å¼•ç”¨ç¬¦ãƒ»åŠè§’æ‹¬å¼§
            r'|[ã€ã€‚ãƒ»,â€¦:;!?ï¼ï¼Ÿï¼/\\|ï¼‹+ï¼Š*.,]'                       # å¥èª­ç‚¹ãƒ»è¨˜å·
            r'|[ã€ã€‘ï¼œï¼ã€Œã€ã€ã€ã€Šã€‹ã€”ã€•ï¼»ï¼½ï½›ï½ï¼ˆï¼‰]'               # å…¨è§’æ‹¬å¼§
            r'|[' + dash_chars + r']'                                   # ãƒã‚¤ãƒ•ãƒ³ãƒ»ãƒ€ãƒƒã‚·ãƒ¥ãƒ»é•·éŸ³
        )
        s = re.sub(pattern, "", s)

    return s


def service_account_client_from_env():
    creds_json = os.getenv("GOOGLE_CREDENTIALS")
    if not creds_json:
        print("âŒ ç’°å¢ƒå¤‰æ•° GOOGLE_CREDENTIALS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", file=sys.stderr)
        sys.exit(2)
    try:
        info = json.loads(creds_json)
    except json.JSONDecodeError as e:
        print(f"âŒ GOOGLE_CREDENTIALS ãŒJSONã¨ã—ã¦èª­ã¿å–ã‚Œã¾ã›ã‚“: {e}", file=sys.stderr)
        sys.exit(2)

    try:
        gc = gspread.service_account_from_dict(info)
        return gc
    except Exception as e:
        print(f"âŒ Google èªè¨¼ã«å¤±æ•—: {e}", file=sys.stderr)
        sys.exit(2)


def open_sheet_by_id(gc, spreadsheet_id: str):
    try:
        sh = gc.open_by_key(spreadsheet_id)
        return sh
    except Exception as e:
        print(f"âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸï¼ˆ{spreadsheet_id}ï¼‰: {e}", file=sys.stderr)
        sys.exit(3)


def ensure_output_worksheet(sh_out, title: str):
    """
    å‡ºåŠ›ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆï¼ˆå½“æ—¥ yymmddï¼‰ã‚’ç¢ºä¿ã€‚ç„¡ã‘ã‚Œã°æ–°è¦ä½œæˆï¼‹ãƒ˜ãƒƒãƒ€ã€‚
    """
    try:
        ws = sh_out.worksheet(title)
    except gspread.WorksheetNotFound:
        ws = sh_out.add_worksheet(title=title, rows=2000, cols=len(OUTPUT_HEADERS))
        ws.append_row(OUTPUT_HEADERS, value_input_option="USER_ENTERED")
    return ws


def read_existing_urls(ws_out):
    """
    æ—¢å­˜URLï¼ˆCåˆ—ï¼‰ã‚’ã‚»ãƒƒãƒˆã§è¿”ã™ï¼ˆãƒ˜ãƒƒãƒ€é™¤ãï¼‰
    """
    values = ws_out.get_all_values()
    urls = set()
    for i, row in enumerate(values):
        if i == 0:
            continue
        if len(row) >= 3:
            url = (row[2] or "").strip()
            if url:
                urls.add(url)
    return urls


def collect_rows_from_input(sh_in, start_jst: datetime, end_jst: datetime):
    """
    å…¥åŠ›ï¼ˆMSNâ†’Googleâ†’Yahooï¼‰ã‹ã‚‰ç¯„å›²ä¸€è‡´ã‚’æŠ½å‡ºã€‚
    å‡ºåŠ›å½¢å¼: [ã‚½ãƒ¼ã‚¹, ã‚¿ã‚¤ãƒˆãƒ«, URL, æŠ•ç¨¿æ—¥(æ•´å½¢), å¼•ç”¨å…ƒ, F, G, æ­£è¦åŒ–ã‚¿ã‚¤ãƒˆãƒ«, æœ‰æ–™ã‚«ãƒ†ã‚´ãƒª]
    """
    out_rows = []

    for sheet_name in INPUT_SHEETS:
        try:
            ws = sh_in.worksheet(sheet_name)
        except gspread.WorksheetNotFound:
            print(f"âš  å…¥åŠ›å´ã«ã‚·ãƒ¼ãƒˆ '{sheet_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        values = ws.get_all_values()
        if not values:
            continue

        for i, row in enumerate(values):
            if i == 0:
                continue
            # A:ã‚¿ã‚¤ãƒˆãƒ«, B:URL, C:æŠ•ç¨¿æ—¥, D:å¼•ç”¨å…ƒ
            title = row[0].strip() if len(row) > 0 else ""
            url = row[1].strip() if len(row) > 1 else ""
            posted_raw = row[2].strip() if len(row) > 2 else ""
            source_name = row[3].strip() if len(row) > 3 else ""

            if not title or not url or not posted_raw:
                continue

            posted_dt = parse_sheet_datetime_to_jst(posted_raw)
            if posted_dt is None:
                continue

            if start_jst <= posted_dt <= end_jst:
                posted_fmt = format_compact_jst(posted_dt)
                norm_title = normalize_title_for_dup(title)
                out_rows.append([
                    sheet_name,         # A: ã‚½ãƒ¼ã‚¹ï¼ˆå…¥åŠ›å…ƒã‚·ãƒ¼ãƒˆåï¼‰
                    title,              # B: ã‚¿ã‚¤ãƒˆãƒ«
                    url,                # C: URL
                    posted_fmt,         # D: æŠ•ç¨¿æ—¥
                    source_name,        # E: å¼•ç”¨å…ƒ
                    "",                 # F: ãƒã‚¸ãƒã‚¬ï¼ˆå¾Œã§AIãŒåŸ‹ã‚ã‚‹ï¼‰
                    "",                 # G: ã‚«ãƒ†ã‚´ãƒªï¼ˆå¾Œã§AIãŒåŸ‹ã‚ã‚‹ï¼‰
                    norm_title,         # H: é‡è¤‡ç¢ºèªç”¨ã‚¿ã‚¤ãƒˆãƒ«
                    ""                  # I: æœ‰æ–™ã‚«ãƒ†ã‚´ãƒª
                ])

    return out_rows


def append_rows_dedup(ws_out, rows, existing_urls):
    """
    æ—¢å­˜URLã¨é‡è¤‡ã—ãªã„ã‚‚ã®ã ã‘è¿½è¨˜
    """
    new_rows = [r for r in rows if (r[2] not in existing_urls)]
    if not new_rows:
        print("âœ… è¿½åŠ å¯¾è±¡ã®æ–°è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆã™ã¹ã¦æ—¢å­˜URLã¨é‡è¤‡ï¼‰ã€‚")
        return 0
    ws_out.append_rows(new_rows, value_input_option="USER_ENTERED")
    print(f"ğŸ“ è¿½åŠ  {len(new_rows)} ä»¶")
    return len(new_rows)


def refresh_h_column_all(ws_out):
    """
    Håˆ—ï¼ˆé‡è¤‡ç¢ºèªç”¨ã‚¿ã‚¤ãƒˆãƒ«ï¼‰ã‚’**å…¨è¡Œ**å†è¨ˆç®—ã—ã¦ä¸Šæ›¸ãã€‚
    è¨˜å·ã®å–ã‚Šã“ã¼ã—ã‚’é˜²ããŸã‚ã€æ¯å›æœ€æ–°ã®æ­£è¦åŒ–ãƒ«ãƒ¼ãƒ«ã§æ›´æ–°ã—ã¾ã™ã€‚
    """
    values = ws_out.get_all_values()
    if len(values) <= 1:
        return
    updates = []
    for i, row in enumerate(values):
        if i == 0:
            continue
        row_idx = i + 1
        title = row[1] if len(row) > 1 else ""
        norm = normalize_title_for_dup(title)
        updates.append({"range": f"H{row_idx}", "values": [[norm]]})
    if updates:
        ws_out.batch_update(updates, value_input_option="USER_ENTERED")


def classify_with_gemini(ws_out):
    """
    Båˆ—ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã‚‚ã¨ã«ã€Fåˆ—ï¼ˆãƒã‚¸ãƒã‚¬ï¼‰/ Gåˆ—ï¼ˆã‚«ãƒ†ã‚´ãƒªï¼‰ã‚’Geminiã§åˆ†é¡ã€‚
    æ—¢ã«F/GãŒåŸ‹ã¾ã£ã¦ã„ã‚‹è¡Œã¯ã‚¹ã‚­ãƒƒãƒ—ã€‚
    """
    api_key = os.getenv("GEMINI_API_KEY", "").strip()
    if not api_key or genai is None:
        print("â„¹ Geminiåˆ†é¡ã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆAPIã‚­ãƒ¼æœªè¨­å®š or ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰ã€‚")
        return

    genai.configure(api_key=api_key)
    values = ws_out.get_all_values()
    if len(values) <= 1:
        return

    items = []  # (row_idx, title)
    for i, row in enumerate(values):
        if i == 0:
            continue
        row_idx = i + 1
        title = row[1] if len(row) > 1 else ""
        f_val = row[5] if len(row) > 5 else ""
        g_val = row[6] if len(row) > 6 else ""
        if title and (not f_val or not g_val):
            items.append((row_idx, title))

    if not items:
        print("â„¹ åˆ†é¡å¯¾è±¡ã®è¡Œã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ====== ã“ã“ãŒå·®ã—æ›¿ãˆãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ ======
    system_prompt = """
ã‚ãªãŸã¯æ•è…•é›‘èªŒè¨˜è€…ã§ã™ã€‚Webãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä»¥ä¸‹ã®è¦å‰‡ã§å³å¯†ã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚

ã€1ã€‘ãƒã‚¸ãƒã‚¬åˆ¤å®šï¼ˆå¿…ãšæ¬¡ã®ã„ãšã‚Œã‹ä¸€èªã®ã¿ï¼‰ï¼š
- ãƒã‚¸ãƒ†ã‚£ãƒ–
- ãƒã‚¬ãƒ†ã‚£ãƒ–
- ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«

ã€2ã€‘è¨˜äº‹ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¤å®šï¼ˆæœ€ã‚‚é–¢é€£ãŒé«˜ã„1ã¤ã ã‘ã‚’é¸ã‚“ã§å‡ºåŠ›ã€‚ä¸¦è¨˜ç¦æ­¢ï¼‰ï¼š
- ä¼šç¤¾ï¼šä¼æ¥­ã®æ–½ç­–ã‚„ç”Ÿç”£ã€è²©å£²å°æ•°ãªã©ã€‚ãƒ‹ãƒƒã‚µãƒ³ã€ãƒˆãƒ¨ã‚¿ã€ãƒ›ãƒ³ãƒ€ã€ã‚¹ãƒãƒ«ã€ãƒãƒ„ãƒ€ã€ã‚¹ã‚ºã‚­ã€ãƒŸãƒ„ãƒ“ã‚·ã€ãƒ€ã‚¤ãƒãƒ„ã®è¨˜äº‹ã®å ´åˆã¯ () ä»˜ãã§ä¼æ¥­åã‚’è¨˜è¼‰ã€‚ãã‚Œä»¥å¤–ã¯ã€Œãã®ä»–ã€ã€‚
- è»Šï¼šã‚¯ãƒ«ãƒã®åç§°ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‚‚ã®ï¼ˆä¼šç¤¾åã ã‘ã®å ´åˆã¯è»Šã«åˆ†é¡ã—ãªã„ï¼‰ã€‚æ–°å‹/ç¾è¡Œ/æ—§å‹ + åç§° ã‚’ () ä»˜ãã§è¨˜è¼‰ï¼ˆä¾‹ï¼šæ–°å‹ãƒªãƒ¼ãƒ•ã€ç¾è¡Œã‚»ãƒ¬ãƒŠã€æ—§å‹ã‚¹ã‚«ã‚¤ãƒ©ã‚¤ãƒ³ï¼‰ã€‚æ—¥ç”£ä»¥å¤–ã®è»Šã®å ´åˆã¯ã€Œè»Šï¼ˆç«¶åˆï¼‰ã€ã¨è¨˜è¼‰ã€‚
- æŠ€è¡“ï¼ˆEVï¼‰ï¼šé›»æ°—è‡ªå‹•è»Šã®æŠ€è¡“ã«é–¢ã‚ã‚‹ã‚‚ã®ï¼ˆãŸã ã—ãƒãƒƒãƒ†ãƒªãƒ¼å·¥å ´å»ºè¨­ã‚„ä¼æ¥­ã®æ–½ç­–ã¯å«ã¾ãªã„ï¼‰ã€‚
- æŠ€è¡“ï¼ˆe-POWERï¼‰ï¼še-POWERã«é–¢ã‚ã‚‹ã‚‚ã®ã€‚
- æŠ€è¡“ï¼ˆe-4ORCEï¼‰ï¼š4WDã‚„2WDã€AWDã«é–¢ã‚ã‚‹ã‚‚ã®ã€‚
- æŠ€è¡“ï¼ˆAD/ADASï¼‰ï¼šè‡ªå‹•é‹è»¢ã‚„å…ˆé€²é‹è»¢ã‚·ã‚¹ãƒ†ãƒ ã«é–¢ã‚ã‚‹ã‚‚ã®ã€‚
- æŠ€è¡“ï¼šä¸Šè¨˜ä»¥å¤–ã®æŠ€è¡“ã«é–¢ã‚ã‚‹ã‚‚ã®ã€‚
- ãƒ¢ãƒ¼ã‚¿ãƒ¼ã‚¹ãƒãƒ¼ãƒ„ï¼šF1ã‚„ãƒ©ãƒªãƒ¼ã€ãƒ•ã‚©ãƒ¼ãƒŸãƒ¥ãƒ©Eãªã©ã€è‡ªå‹•è»Šãƒ¬ãƒ¼ã‚¹ã«é–¢ã‚ã‚‹ã‚‚ã®ã€‚
- æ ªå¼ï¼šæ ªå¼ç™ºè¡Œã‚„æ ªä¾¡ã®å€¤å‹•ãã€æŠ•è³‡ã«é–¢ã‚ã‚‹ã‚‚ã®ã€‚
- æ”¿æ²»ãƒ»çµŒæ¸ˆï¼šæ”¿æ²»å®¶ã‚„é¸æŒ™ã€ç¨é‡‘ã€çµŒæ¸ˆã«é–¢ã‚ã‚‹ã‚‚ã®ã€‚
- ã‚¹ãƒãƒ¼ãƒ„ï¼šé‡çƒã‚„ã‚µãƒƒã‚«ãƒ¼ã€ãƒãƒ¬ãƒ¼ãƒœãƒ¼ãƒ«ãªã©è‡ªå‹•è»Šä»¥å¤–ã®ã‚¹ãƒãƒ¼ãƒ„ã«é–¢ã‚ã‚‹ã‚‚ã®ã€‚
- ãã®ä»–ï¼šä¸Šè¨˜ã«å«ã¾ã‚Œãªã„ã‚‚ã®ã€‚

ã€å‡ºåŠ›è¦ä»¶ã€‘
- **JSONé…åˆ—**ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ï¼ˆä½™è¨ˆãªæ–‡ç« ã‚„æ³¨é‡ˆã¯å‡ºåŠ›ã—ãªã„ï¼‰ã€‚
- å„è¦ç´ ã¯æ¬¡ã®å½¢å¼ï¼š{"row": è¡Œç•ªå·, "sentiment": "ãƒã‚¸ãƒ†ã‚£ãƒ–|ãƒã‚¬ãƒ†ã‚£ãƒ–|ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«", "category": "ã‚«ãƒ†ã‚´ãƒªå"}
- å…¥åŠ›ã®ã€Œã‚¿ã‚¤ãƒˆãƒ«ã€æ–‡å­—åˆ—ã¯ä¸€åˆ‡å¤‰æ›´ã—ãªã„ã“ã¨ï¼ˆå‡ºåŠ›ã«ã¯å«ã‚ãªãã¦è‰¯ã„ï¼‰ã€‚
""".strip()
    # =====================================

    BATCH = 40
    updates = []
    for start in range(0, len(items), BATCH):
        batch = items[start : start + BATCH]
        payload = [{"row": r, "title": t} for (r, t) in batch]
        try:
            model = genai.GenerativeModel("gemini-1.5-flash")
            prompt = system_prompt + "\n\n" + json.dumps(payload, ensure_ascii=False, indent=2)
            resp = model.generate_content(prompt)
            text = (resp.text or "").strip()

            # JSONæŠ½å‡ºï¼ˆå¿œç­”ã«å‰å¾Œæ–‡ãŒæ··ã–ã‚‹ä¿é™ºï¼‰
            import re as re_std
            m = re_std.search(r"\[.*\]", text, flags=re_std.DOTALL)
            json_text = m.group(0) if m else text
            result = json.loads(json_text)

            for obj in result:
                try:
                    row_idx = int(obj.get("row"))
                except Exception:
                    continue
                sentiment = str(obj.get("sentiment", "")).strip()
                category = str(obj.get("category", "")).strip()

                # æœŸå¾…èªå½™ã«è»½ãå¯„ã›ã‚‹ï¼ˆå…¨è§’ãƒ»å‰å¾Œç©ºç™½ãªã©ï¼‰
                if sentiment not in ("ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"):
                    # ç°¡æ˜“æ­£è¦åŒ–ï¼ˆèª¤è¨˜ãƒªã‚«ãƒãƒªï¼‰
                    if "ãƒã‚¸" in sentiment:
                        sentiment = "ãƒã‚¸ãƒ†ã‚£ãƒ–"
                    elif "ãƒã‚¬" in sentiment:
                        sentiment = "ãƒã‚¬ãƒ†ã‚£ãƒ–"
                    else:
                        sentiment = "ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«"

                updates.append({
                    "range": f"F{row_idx}:G{row_idx}",   # F=ãƒã‚¸ãƒã‚¬, G=ã‚«ãƒ†ã‚´ãƒª
                    "values": [[sentiment, category]]
                })
        except Exception as e:
            print(f"âš  Geminiå¿œç­”ã®è§£æã«å¤±æ•—: {e}")

    if updates:
        ws_out.batch_update(updates, value_input_option="USER_ENTERED")
        print(f"âœ¨ Geminiåˆ†é¡ã‚’ {len(updates)} è¡Œã«åæ˜ ã—ã¾ã—ãŸã€‚")
    else:
        print("â„¹ Geminiåˆ†é¡ã®æ›´æ–°ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


def main():
    now = jst_now()
    date_sheet = yymmdd_jst(now)
    start_jst, end_jst = calc_time_window(now)

    print(f"ğŸ“… æœŸé–“: {start_jst.strftime('%Y/%m/%d %H:%M:%S')} ã€œ {end_jst.strftime('%Y/%m/%d %H:%M:%S')} (JST)")
    print(f"ğŸ—’ å‡ºåŠ›ã‚·ãƒ¼ãƒˆå: {date_sheet}")

    gc = service_account_client_from_env()
    sh_in = open_sheet_by_id(gc, INPUT_SPREADSHEET_ID)
    sh_out = open_sheet_by_id(gc, OUTPUT_SPREADSHEET_ID)

    # å…¥åŠ›ã‹ã‚‰æŠ½å‡º
    extracted = collect_rows_from_input(sh_in, start_jst, end_jst)
    print(f"ğŸ” æŠ½å‡ºåˆè¨ˆ: {len(extracted)} ä»¶")

    # å‡ºåŠ›ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆç¢ºä¿
    ws_out = ensure_output_worksheet(sh_out, date_sheet)

    # æ—¢å­˜URLåé›†ï¼ˆCåˆ—ï¼‰
    existing = read_existing_urls(ws_out)
    print(f"ğŸ§® æ—¢å­˜URLæ•°: {len(existing)} ä»¶")

    # è¿½è¨˜ï¼ˆé‡è¤‡é™¤å¤–ï¼‰
    added = append_rows_dedup(ws_out, extracted, existing)

    # Håˆ—ã‚’æ¯å›**å…¨è¡Œ**å†è¨ˆç®—ï¼ˆæ­£è¦åŒ–ãƒ«ãƒ¼ãƒ«ã®æœ€æ–°åæ˜ ï¼‰
    refresh_h_column_all(ws_out)

    # Geminiåˆ†é¡ï¼ˆF/Gåˆ—ã‚’åŸ‹ã‚ã‚‹ï¼‰
    classify_with_gemini(ws_out)

    print("âœ… å®Œäº†")
    if added:
        print(f"âœ¨ æ–°è¦è¿½åŠ : {added} ä»¶")
    else:
        print("âœ¨ è¿½åŠ ãªã—")


if __name__ == "__main__":
    main()
